{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ojEHCr4m82O"
   },
   "source": [
    "<b>Importing the libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYKaEFcOsNWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0REjl6umFDV"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlU0bvex2tZ-"
   },
   "source": [
    "<b>Pre-Processing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fjij_nX2-gI"
   },
   "source": [
    "Here I have used a preprocessed corpus done in the preprocessing notebook. I have performed steps like removing citations, email addresses, urls , parenthesis, numbers and special characters which I feel will give me good results for a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5StOQLQhsQB7"
   },
   "outputs": [],
   "source": [
    "#Loading the preprocessed Corpus\n",
    "corpus = pd.read_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PRnCneGJVB0"
   },
   "source": [
    "##1. Trigram Language Model\n",
    "\n",
    "Here I have used dictionary to keep the count of trigrams in the corpus with which I have assigned probablities for each such trigram i.e. (w1, w2 , w3) is a trigram then we can get calculate <b>P</b>(w3| w1, w2) using the count of each such trigram divided by the total count of (w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PByBwrRPmu85"
   },
   "outputs": [],
   "source": [
    "# Create a placeholder dictionary for model (assigning probablities)\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhRX_2R6l-0R"
   },
   "outputs": [],
   "source": [
    "for i,j in corpus['processed'].iteritems():\n",
    "  if type(j)==str:\n",
    "    sent = sent_tokenize(j)\n",
    "    for k in sent:\n",
    "      words = word_tokenize(k)\n",
    "      for w1, w2, w3 in trigrams(words, pad_right=True, pad_left=True):\n",
    "        model[(w1, w2)][w3] += 1\n",
    "\n",
    " \n",
    "# transforming counts to probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Jkl0NCrKyjF"
   },
   "source": [
    "<b>2. Generating Sentences using trigram model</b>\n",
    "\n",
    "Using the above built model, here I have generated a sentences using the starting two words. Since 'the' is the most common term in the corpus, I have generated sentences starting from 'the' followed by some common occuring words. I have again used the same words with 4-gram model to make a comparison. I have first selected a random threshold to filter out my next term and then using that I am accumulating words from previous two words to generate a sentence. Here us the result that I have obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fYwOIst2dvn",
    "outputId": "d2a45968-88b0-4632-bb6e-7489afd7bcda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the study authors were able to rescue stop codon resulting in a regulatory role in the range of possible directions which can be evaluated with caution is advised in using digital inline holography i.e .\n",
      "the role of the nasal washes among previously healthy 60yearold man from human activity in progressive destruction of the hyperechogenic posterior wall of the population in punjab are compared with monotherapy or rimantadinenebulized zanamivir combination therapy also occurred since hospitalization and others of which are manned by a human monoclonal igm antibody but the risk of increasing rates of older adults .\n",
      "the virus tended to adhere to this disease spread .\n"
     ]
    }
   ],
   "source": [
    "# starting words\n",
    "start = [[\"the\",\"study\"],[\"the\",\"role\"],[\"the\",\"virus\"]]\n",
    "\n",
    "for text in start:\n",
    "  sentence_finished = False\n",
    "\n",
    "  while not sentence_finished:\n",
    "    # selecting a random probability threshold  \n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "\n",
    "    for word in model[tuple(text[-2:])].keys():\n",
    "      accumulator += model[tuple(text[-2:])][word]\n",
    "      # selecting words that are above the probability threshold\n",
    "      if accumulator >= r:\n",
    "          text.append(word)\n",
    "          break\n",
    "\n",
    "    if text[-2:] == [None, None]:\n",
    "      sentence_finished = True\n",
    " \n",
    "  print (' '.join([t for t in text if t]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QkVXqCJMSc3"
   },
   "source": [
    "##3. 4-gram Language Model\n",
    "\n",
    "Similar to the trigram model, I have used dictionary to keep the count of 4-grams in the corpus with which I have assigned probablities for each such 4-gram i.e. (w1, w2 , w3, w4) to calculate <b>P</b>(w4| w1, w2, w3) using the count of each such 4-gram divided by the total count of (w1, w2,w3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK5JHuRqpQKN"
   },
   "outputs": [],
   "source": [
    "model4 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for i,j in corpus['processed'].iteritems():\n",
    "  if type(j)==str:\n",
    "    sent = sent_tokenize(j)\n",
    "    for k in sent:\n",
    "      words = word_tokenize(k)\n",
    "      for w1, w2, w3, w4 in ngrams(words, 4, pad_right=True, pad_left=True):\n",
    "        model4[(w1, w2, w3)][w4] += 1\n",
    "\n",
    " \n",
    "# tranformation of counts to probabilities\n",
    "for w1_w2_w3 in model4:\n",
    "    total_count = float(sum(model4[w1_w2_w3].values()))\n",
    "    for w4 in model4[w1_w2_w3]:\n",
    "        model4[w1_w2_w3][w4] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SunWMBBGMsOe"
   },
   "source": [
    "<b>4. Generating Sentences using 4-gram model</b>\n",
    "\n",
    "I have again used the same starting words as in the trigram model to make an comparison. Since this model requires 3 starting words, I have used the third word as generated in the trigram model to generate sentences. Here is the result that I have obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TRCC8VrGlhL",
    "outputId": "eef9d895-1935-45a3-c594-5463d4b7ea75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the study authors found no published studies comparing the cbc indices cardiac and coagulation parameters electrolyte factors renal and liver damage .\n",
      "the role of lipid pathways in covid19 in more narrowly constructed samples .\n"
     ]
    }
   ],
   "source": [
    "# starting words\n",
    "start = [[\"the\",\"study\",\"authors\"],[\"the\",\"role\",\"of\"]]\n",
    "\n",
    "for text in start:\n",
    "  sentence_finished = False\n",
    "\n",
    "  while not sentence_finished:\n",
    "    # selecting a random probability threshold  \n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "\n",
    "    for word in model4[tuple(text[-3:])].keys():\n",
    "      accumulator += model4[tuple(text[-3:])][word]\n",
    "      # selecting words that are above the probability threshold\n",
    "      if accumulator >= r:\n",
    "          text.append(word)\n",
    "          break\n",
    "\n",
    "    if text[-2:] == [None, None]:\n",
    "      sentence_finished = True\n",
    " \n",
    "  print (' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_ISs6ZjP7n5"
   },
   "source": [
    "Apparent problem in this ngram model is the data sparseness. Though I am building the model by maintaining a dictionary which doesnot keep count of the 0 count terms, it can be further optimized by using thresholds to filter out less frequent terms and maintaing small dictionaries which can also take advantage of parallelization."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP-Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
